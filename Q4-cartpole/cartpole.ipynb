{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "isTrain = False\n",
    "render = False\n",
    "weights = 'cartpole.h5'\n",
    "min_explore = 0.01\n",
    "explore_rate = 1.0\n",
    "decay = 0.995\n",
    "num_episodes =10000\n",
    "num_evals = 100\n",
    "gamma = 0.95\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# make model\n",
    "env = gym.make('CartPole-v0')\n",
    "history = deque(maxlen=1000)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=4, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved weights in not in training mode\n",
    "if(not isTrain):\n",
    "    if os.path.isfile(weights):\n",
    "        model.load_weights(weights)\n",
    "        explore_rate = min_explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to update model\n",
    "def update_model():\n",
    "    global explore_rate\n",
    "    if len(history) < batch_size: #Start training only when queue has min batch size entries\n",
    "        return\n",
    "    sample_batch = random.sample(history, batch_size)\n",
    "    for state, action, reward, next_state, done in sample_batch:\n",
    "        target = reward\n",
    "        if not done:\n",
    "          target = reward + gamma * np.amax(model.predict(next_state)[0]) #Get target from next state prediction\n",
    "        target_f = model.predict(state) # from current state\n",
    "        target_f[0][action] = target \n",
    "        model.fit(state, target_f, epochs=1, verbose=0)\n",
    "    if explore_rate > min_explore: # Reduce the explore rate after each batch train\n",
    "        explore_rate *= decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to infer model\n",
    "def infer(state):\n",
    "    if np.random.rand() <= explore_rate: #Use Model or Random Number based on current explore rate\n",
    "        return random.randrange(2) #Random number 0 or 1\n",
    "    vals = model.predict(state)\n",
    "    return np.argmax(vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train model\n",
    "def run_train():\n",
    "    try:\n",
    "        for index_episode in range(1,num_episodes+1):\n",
    "            state = env.reset()\n",
    "            state = np.reshape(state, [1, 4])\n",
    "            done = False\n",
    "            currRewards = 0\n",
    "            while not done:\n",
    "                if(render):\n",
    "                    env.render()\n",
    "                action = infer(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, 4])\n",
    "                history.append((state, action, reward, next_state, done))\n",
    "                state = next_state\n",
    "                currRewards += reward\n",
    "            print(\"Episode {}# Score: {}\".format(index_episode, currRewards))\n",
    "            update_model()\n",
    "    finally:\n",
    "        model.save(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate model\n",
    "# cartpole is solved if avg score is greater than 195 for 100 consecutive runs\n",
    "def eval():\n",
    "    AvgReward = 0\n",
    "    for index_episode in range(1,num_evals+1):\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, 4])\n",
    "        done = False\n",
    "        currEvalRewards = 0\n",
    "        while not done:\n",
    "            if(render):\n",
    "                env.render()\n",
    "            action = infer(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, 4])\n",
    "            state = next_state\n",
    "            currEvalRewards += reward\n",
    "        AvgReward += currEvalRewards\n",
    "        print(\"Episode {}# Score: {}\".format(index_episode, currEvalRewards))\n",
    "        print(\"Avg Score: {}\".format(AvgReward/(index_episode)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 2# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 3# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 4# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 5# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 6# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 7# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 8# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 9# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 10# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 11# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 12# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 13# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 14# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 15# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 16# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 17# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 18# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 19# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 20# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 21# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 22# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 23# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 24# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 25# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 26# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 27# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 28# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 29# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 30# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 31# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 32# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 33# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 34# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 35# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 36# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 37# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 38# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 39# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 40# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 41# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 42# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 43# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 44# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 45# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 46# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 47# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 48# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 49# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 50# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 51# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 52# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 53# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 54# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 55# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 56# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 57# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 58# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 59# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 60# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 61# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 62# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 63# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 64# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 65# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 66# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 67# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 68# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 69# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 70# Score: 200.0\n",
      "Avg Score: 200.0\n",
      "Episode 71# Score: 169.0\n",
      "Avg Score: 199.56338028169014\n",
      "Episode 72# Score: 200.0\n",
      "Avg Score: 199.56944444444446\n",
      "Episode 73# Score: 200.0\n",
      "Avg Score: 199.57534246575344\n",
      "Episode 74# Score: 200.0\n",
      "Avg Score: 199.5810810810811\n",
      "Episode 75# Score: 200.0\n",
      "Avg Score: 199.58666666666667\n",
      "Episode 76# Score: 200.0\n",
      "Avg Score: 199.5921052631579\n",
      "Episode 77# Score: 200.0\n",
      "Avg Score: 199.5974025974026\n",
      "Episode 78# Score: 200.0\n",
      "Avg Score: 199.60256410256412\n",
      "Episode 79# Score: 200.0\n",
      "Avg Score: 199.60759493670886\n",
      "Episode 80# Score: 200.0\n",
      "Avg Score: 199.6125\n",
      "Episode 81# Score: 200.0\n",
      "Avg Score: 199.6172839506173\n",
      "Episode 82# Score: 200.0\n",
      "Avg Score: 199.6219512195122\n",
      "Episode 83# Score: 200.0\n",
      "Avg Score: 199.6265060240964\n",
      "Episode 84# Score: 200.0\n",
      "Avg Score: 199.63095238095238\n",
      "Episode 85# Score: 200.0\n",
      "Avg Score: 199.63529411764705\n",
      "Episode 86# Score: 200.0\n",
      "Avg Score: 199.63953488372093\n",
      "Episode 87# Score: 200.0\n",
      "Avg Score: 199.64367816091954\n",
      "Episode 88# Score: 200.0\n",
      "Avg Score: 199.64772727272728\n",
      "Episode 89# Score: 200.0\n",
      "Avg Score: 199.65168539325842\n",
      "Episode 90# Score: 200.0\n",
      "Avg Score: 199.65555555555557\n",
      "Episode 91# Score: 200.0\n",
      "Avg Score: 199.65934065934067\n",
      "Episode 92# Score: 200.0\n",
      "Avg Score: 199.66304347826087\n",
      "Episode 93# Score: 200.0\n",
      "Avg Score: 199.66666666666666\n",
      "Episode 94# Score: 200.0\n",
      "Avg Score: 199.67021276595744\n",
      "Episode 95# Score: 200.0\n",
      "Avg Score: 199.67368421052632\n",
      "Episode 96# Score: 200.0\n",
      "Avg Score: 199.67708333333334\n",
      "Episode 97# Score: 200.0\n",
      "Avg Score: 199.68041237113403\n",
      "Episode 98# Score: 200.0\n",
      "Avg Score: 199.68367346938774\n",
      "Episode 99# Score: 200.0\n",
      "Avg Score: 199.68686868686868\n",
      "Episode 100# Score: 200.0\n",
      "Avg Score: 199.69\n"
     ]
    }
   ],
   "source": [
    "if(isTrain):\n",
    "    run_train()\n",
    "else:\n",
    "    eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
